{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "invalid-imaging",
   "metadata": {},
   "source": [
    "# ADA (Automatic Data Analysis) - Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "plain-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287de09",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06d1e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE Z VALUE\n",
    "def get_z(confidence_level:float)->float:\n",
    "    \"\"\"\n",
    "    Calculate Z value for a given confidence level.\n",
    "    \n",
    "    confidence_level -- confidence level into percent. \n",
    "    return -- z value.\n",
    "    \"\"\"\n",
    "    return st.norm.ppf(1-(1-confidence_level/100.)/2)\n",
    "\n",
    "\n",
    "# CALCULATE THE SAMPLE SIZE\n",
    "def sample_size(population_size:int, confidence_level:float, confidence_interval:float):\n",
    "    \"\"\"\n",
    "    Calculate the sample size using the Cochran’s Sample Size Formula.\n",
    "    \n",
    "    population_size -- the total population size.\n",
    "    confidence_level -- the seleceted confidence level in percent. \n",
    "    confidence_interval -- the selected confidence interval in percent.\n",
    "    return -- sample size with the correction for smaller population (no large).\n",
    "    \"\"\"\n",
    "    Z = 0.0\n",
    "    p = 0.5\n",
    "    e = confidence_interval/100.0\n",
    "    N = population_size\n",
    "    n_0 = 0.0\n",
    "    n = 0.0\n",
    "\n",
    "    # FIND THE NUM STD DEVIATIONS FOR THAT CONFIDENCE LEVEL\n",
    "    Z = get_z(confidence_level)\n",
    "\n",
    "    if Z == 0.0:\n",
    "        return -1\n",
    "\n",
    "    # CALC SAMPLE SIZE\n",
    "    n_0 = ((Z**2) * p * (1-p)) / (e**2)\n",
    "\n",
    "    # ADJUST SAMPLE SIZE FOR FINITE POPULATION\n",
    "    n = n_0 / (1 + ((n_0 - 1) / float(N)) )\n",
    "\n",
    "    return int(math.ceil(n)) # THE SAMPLE SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1317143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove outliers of a 1D array according to the Inter Quartile Range (IQR)\n",
    "def remove_outliers(df:pd.DataFrame, colname:str, verbose:bool = False)->(np.array, list):\n",
    "    # get data\n",
    "    v = df[colname].values\n",
    "    # estimate boundary thresholds\n",
    "    Q1 = np.quantile(v,0.25)\n",
    "    Q3 = np.quantile(v,0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    t_lower = Q1 - 1.5*IQR\n",
    "    t_upper = Q3 + 1.5*IQR\n",
    "    # report preparation\n",
    "    reports = list()\n",
    "    noutliers_down = v[v < t_lower].shape[0]\n",
    "    noutliers_up = v[v > t_upper].shape[0]\n",
    "    if  noutliers_down > 0:\n",
    "        reports.append(f'It was removed {noutliers_down} outliers: \"{colname}\" < {t_lower}') \n",
    "    if  noutliers_up > 0:\n",
    "        reports.append(f'It was removed {noutliers_up} outliers: \"{colname}\" > {t_upper}')             \n",
    "    # display\n",
    "    if verbose:\n",
    "        print(f'It was removed {noutliers_down} outliers: \"{colname}\" < {t_lower}')\n",
    "        print(f'It was removed {noutliers_up} outliers: \"{colname}\" > {t_upper}')\n",
    "    # remove values outside of these thresholds and return\n",
    "    v[v < t_lower] = np.nan\n",
    "    v[v > t_upper] = np.nan\n",
    "    # replace column\n",
    "    df[colname] = df[colname]\n",
    "    # return\n",
    "    return df, reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "49a883c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## categorical values conversion\n",
    "def conversion_categorical_values(df:pd.DataFrame, col:str)->(pd.DataFrame, dict):\n",
    "    # rename column\n",
    "    df.rename(columns = {col:'original'}, inplace = True)\n",
    "    # factorize\n",
    "    df[col] = pd.factorize(df['original'])[0]\n",
    "    # as str\n",
    "    df[col] = df[col].astype(str)\n",
    "    # create conversor\n",
    "    dcat = df[['original', col]].drop_duplicates().set_index(col).to_dict()['original']\n",
    "    # remove original column\n",
    "    df.drop('original', axis = 1, inplace = True)\n",
    "    # return\n",
    "    return (df, dcat)\n",
    "\n",
    "\n",
    "## simplify dataset\n",
    "def data_simplify(raw:pd.DataFrame)->(pd.DataFrame, dict, dict):\n",
    "    # copy \n",
    "    data = raw.copy()\n",
    "    # get columns\n",
    "    cols = Columns(data)\n",
    "    # initialize\n",
    "    dcols_name_to_alias = dict()\n",
    "    dcols_alias_to_name = dict()\n",
    "    # columns name converters: numerical\n",
    "    if len(cols.num)>0:\n",
    "        for i, ic in enumerate(cols.num):\n",
    "            dcols_name_to_alias[ic] = 'n{}'.format(i)\n",
    "            dcols_alias_to_name['n{}'.format(i)] = ic\n",
    "    # columns name converters: categorical\n",
    "    if len(cols.cat)>0:\n",
    "        for i, ic in enumerate(cols.cat):\n",
    "            dcols_name_to_alias[ic] = 'c{}'.format(i)\n",
    "            dcols_alias_to_name['c{}'.format(i)] = ic\n",
    "    # columns name converters: ordinal\n",
    "    if len(cols.ord)>0:\n",
    "        for i, ic in enumerate(cols.ord):\n",
    "            dcols_name_to_alias[ic] = 'o{}'.format(i)\n",
    "            dcols_alias_to_name['o{}'.format(i)] = ic\n",
    "    # rename columns\n",
    "    data.rename(columns = dcols_name_to_alias, inplace = True)\n",
    "    # get columns\n",
    "    cols_new = Columns(data)\n",
    "    # initialize\n",
    "    d_converter_cat_values = dict()\n",
    "    # loop of categorical columns\n",
    "    for col in cols_new.cat:\n",
    "        data, d_converter_cat_values[col] = conversion_categorical_values(data, col)\n",
    "    # return\n",
    "    return (data, dcols_alias_to_name, d_converter_cat_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35137196",
   "metadata": {},
   "source": [
    "## classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c991795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Columns():\n",
    "    # constructor\n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.num = df.select_dtypes(include=['float64']).columns.values  # numerical columns\n",
    "        self.ord = df.select_dtypes(include=['int64']).columns.values    # numerical columns\n",
    "        self.cat = df.select_dtypes(include=['object']).columns.values   # categorical columns  \n",
    "        \n",
    "    # printer\n",
    "    def __str__(self):\n",
    "        return f'Categorical: {self.cat} \\nNumerical: {self.num} \\nOrdinal: {self.ord}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3aef9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report():\n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        self.records = list()\n",
    "        \n",
    "    # add new record\n",
    "    def add(self, new_record:'str or list'):\n",
    "        # validate if is a str or list\n",
    "        if type(new_record) == str:\n",
    "            new_record = [new_record]\n",
    "        # add new record\n",
    "        self.records += new_record\n",
    "        \n",
    "    # display records\n",
    "    def display(self, max_records:int = None):\n",
    "        for i, record in enumerate(self.records):\n",
    "            # display record\n",
    "            print(f'[{i}] {record}')\n",
    "            # stop display\n",
    "            if not max_records is None and i == max_records:\n",
    "                break\n",
    "    \n",
    "    # count number of records\n",
    "    def count(self):\n",
    "        # display\n",
    "        print(f'Number of records = {len(self.records)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-thesaurus",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "reduced-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = load_iris()\n",
    "dataset.keys()\n",
    "# dataset to df\n",
    "raw = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "raw['class'] = dataset.target\n",
    "dclass = dict()\n",
    "for i, ic in enumerate(dataset.target_names):\n",
    "    dclass[i] = ic\n",
    "raw['class'] = raw['class'].map(dclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-colorado",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d2b0e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize report\n",
    "REPORT = Report()\n",
    "# dataset simplification\n",
    "data, dcols_alias_to_name, d_converter_cat_values = data_simplify(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3731557",
   "metadata": {},
   "source": [
    "### remove outliers in numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "087e89b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was removed 0 outliers: \"n0\" < 3.1499999999999986\n",
      "It was removed 0 outliers: \"n0\" > 8.350000000000001\n",
      "It was removed 1 outliers: \"n1\" < 2.05\n",
      "It was removed 3 outliers: \"n1\" > 4.05\n",
      "It was removed 0 outliers: \"n2\" < -3.649999999999999\n",
      "It was removed 0 outliers: \"n2\" > 10.349999999999998\n",
      "It was removed 0 outliers: \"n3\" < -1.95\n",
      "It was removed 0 outliers: \"n3\" > 4.05\n"
     ]
    }
   ],
   "source": [
    "# get columns\n",
    "cols = Columns(data)\n",
    "# loop of num columns\n",
    "for c in cols.num:\n",
    "    # remove outliers (JUAN: hay que incluir reports en el sistema)\n",
    "    data, ireports = remove_outliers(data, c, verbose = True)\n",
    "    # add to report\n",
    "    REPORT.add(ireports)\n",
    "    # clean\n",
    "    del ireports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc19ffd",
   "metadata": {},
   "source": [
    "# Queries combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "24c50be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more categorical variables [PARA TESTING]\n",
    "#data['c1'] = data['n1'].apply(lambda x: str(int(x)))\n",
    "#data['c2'] = data['n2'].apply(lambda x: str(int(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "17f95bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize final lists with single queries\n",
    "LIST_QUERIES = list()\n",
    "LIST_INDEX = list()\n",
    "# initialize\n",
    "n = 0\n",
    "cols = Columns(data)\n",
    "\n",
    "## variables combination\n",
    "\n",
    "# all possible combinations between variables\n",
    "per_cols = list()\n",
    "for i in range(1,len(cols.cat)+1,1):\n",
    "    per_cols += list(itertools.permutations(list(cols.cat),r=i))\n",
    "\n",
    "## singles queries\n",
    "\n",
    "# initialize\n",
    "dsingle_queries = dict()\n",
    "# get single queries\n",
    "for iper_cols in per_cols:\n",
    "    dsingle_queries[iper_cols[0]] = [f\"{iper_cols[0]} == '{cat}'\" for cat in sorted(list(data[iper_cols[0]].unique()))]\n",
    "\n",
    "# loop of single queries\n",
    "for c in dsingle_queries:\n",
    "    # add single queries\n",
    "    LIST_QUERIES += dsingle_queries[c]\n",
    "    # add their indexes\n",
    "    LIST_INDEX += [n for i in range(len(dsingle_queries[c]))]\n",
    "    # add to index\n",
    "    n+=1\n",
    "    \n",
    "## non single queries\n",
    "\n",
    "# get combination queries\n",
    "for iper_cols in [pc for pc in per_cols if len(pc)>1]:\n",
    "    # combine list of single queries\n",
    "    isingle_queries = list()\n",
    "    for c in iper_cols:\n",
    "        isingle_queries += dsingle_queries[c]\n",
    "    # get all possible combinations\n",
    "    comb = list(itertools.combinations(isingle_queries,r=len(iper_cols)))\n",
    "    # initialize\n",
    "    final_comb = list()\n",
    "    # loop of combinations\n",
    "    for ic in comb:\n",
    "        # create final query\n",
    "        icomb = ' & '.join(ic)\n",
    "        # append only necessary queries\n",
    "        if np.prod([c in icomb for c in iper_cols]):\n",
    "            final_comb.append(icomb)\n",
    "    # sort and append to the final list\n",
    "    final_comb = sorted(final_comb)\n",
    "    LIST_QUERIES += final_comb\n",
    "    \n",
    "    # estimate their indexes\n",
    "    l = [c.split(f' & {iper_cols[-1]}')[:-1] for c in final_comb]\n",
    "    ln = [n]\n",
    "    for i in range(len(l)-1):\n",
    "        if l[i] != l[i+1]:\n",
    "            n += 1\n",
    "        ln.append(n) \n",
    "    # add indexes to the final list\n",
    "    LIST_INDEX += ln\n",
    "    \n",
    "# store queries in a df\n",
    "dfqueries = pd.DataFrame({'query':LIST_QUERIES, 'number':LIST_INDEX})\n",
    "\n",
    "\n",
    "## add number of records per query\n",
    "\n",
    "# initialize\n",
    "LIST_SIZES = list()\n",
    "# loop of queries\n",
    "for squery in dfqueries['query'].values:\n",
    "    LIST_SIZES.append(len(data.query(squery)))\n",
    "# add new columnt\n",
    "dfqueries['sample_size'] = LIST_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "222b33a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>number</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0 == '0'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0 == '1'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0 == '2'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  number  sample_size\n",
       "0  c0 == '0'       0           50\n",
       "1  c0 == '1'       0           50\n",
       "2  c0 == '2'       0           50"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfqueries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736a7bd",
   "metadata": {},
   "source": [
    "# Filter queries by min size of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "423b9e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE SIZE: 109 from 150\n",
      "Number of queries after filtering = 3\n"
     ]
    }
   ],
   "source": [
    "# estimate minimun size of sample\n",
    "population_sz = len(data)\n",
    "confidence_level = 95.0\n",
    "confidence_interval = 5.0\n",
    "n_min_sample_size = sample_size(population_sz, confidence_level, confidence_interval)\n",
    "print(\"SAMPLE SIZE: %d from %d\" %(n_min_sample_size, population_sz))\n",
    "# FOR TESTING\n",
    "n_min_sample_size = 50\n",
    "# filter queries\n",
    "dfqueries = dfqueries[dfqueries.sample_size>=n_min_sample_size]\n",
    "print(f'Number of queries after filtering = {len(dfqueries)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d1d2082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>number</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0 == '0'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0 == '1'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0 == '2'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  number  sample_size\n",
       "0  c0 == '0'       0           50\n",
       "1  c0 == '1'       0           50\n",
       "2  c0 == '2'       0           50"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfqueries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eae1ef",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f5a97798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get combinations of numerical variables (JUAN: en este caso solo combinaciones num - num)\n",
    "comb_num_num = list(itertools.combinations(list(cols.num),r=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "da7d3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get set of queries\n",
    "numbers_query_sets = sorted(list(dfqueries['number'].unique()))\n",
    "\n",
    "# loop of numbers of query sets\n",
    "number = numbers_query_sets[0] # JUAN: in this case the first set\n",
    "\n",
    "# get queries for this set\n",
    "queries = dfqueries[dfqueries['number'] == number]['query'].tolist()\n",
    "\n",
    "# get variables to remove of being analysed (JUAN in this case only numerical)\n",
    "cols_all = data.columns.tolist()\n",
    "cols_remove = [c for c in cols_all if c in queries[0]]\n",
    "cols_num = [c for c in cols.num if not c in cols_remove]\n",
    "\n",
    "# initialize samples\n",
    "dsamples = dict()\n",
    "\n",
    "# get samples per set\n",
    "for squery in queries[:1]:\n",
    "    # get sample\n",
    "    dsamples[squery] = data.query(squery)[cols_num]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698dd3cf",
   "metadata": {},
   "source": [
    "## num - num (entre columnas)\n",
    "\n",
    "- https://datascience.stackexchange.com/questions/64260/pearson-vs-spearman-vs-kendall/64261"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9f154baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('n0', 'n1')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop of num-num combinations (JUAN: in this case just the first combination)\n",
    "icomb_num_num = comb_num_num[0]\n",
    "icomb_num_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeabe83",
   "metadata": {},
   "source": [
    "### full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c36e2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get combination of columns\n",
    "col_x = list(icomb_num_num)\n",
    "# collect data and remove nan values\n",
    "temp = data[col_x].dropna()\n",
    "# check if there enough data to analyze\n",
    "#if len(temp) < n_min_sample_size:\n",
    "    # JUAN: stop analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cc4b16e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      n0   n1\n",
       "0    5.1  3.5\n",
       "1    4.9  3.0\n",
       "2    4.7  3.2\n",
       "3    4.6  3.1\n",
       "4    5.0  3.6\n",
       "..   ...  ...\n",
       "145  6.7  3.0\n",
       "146  6.3  2.5\n",
       "147  6.5  3.0\n",
       "148  6.2  3.4\n",
       "149  5.9  3.0\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e49c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a7abfbe",
   "metadata": {},
   "source": [
    "### for a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2264fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
